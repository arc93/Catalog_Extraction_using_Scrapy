{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import scrapy\n",
    "import logging\n",
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy import signals\n",
    "import csv\n",
    "\n",
    "#logging.getLogger('scrapy').propagate = False\n",
    "class CatalogSpider(scrapy.Spider):\n",
    "\n",
    "    name = \"catalogdata\"\n",
    "    start_urls = [\"http://dmoztools.net/Arts/Animation/Anime/Titles/3/3%C3%973_Eyes/\",\n",
    "                  \"http://dmoztools.net/Computers/Software/Databases/Data_Warehousing/Consultants/\",\n",
    "                  \"http://dmoztools.net/Health/Animal/Drugs_and_Medications/\",\n",
    "                  \"http://dmoztools.net/Health/Animal/Veterinary_Medicine/\",\n",
    "                  \"http://dmoztools.net/Health/Animal/Alternative_Medicine/\",\n",
    "                  \"http://dmoztools.net/Health/Medicine/Evidence_Based_Medicine/\"\n",
    "                 ]\n",
    "    itemlist = []\n",
    "\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        spider = super().from_crawler(crawler)\n",
    "        crawler.signals.connect(spider.spider_closed, signals.spider_closed)\n",
    "        return spider\n",
    "\n",
    "    \n",
    "    #csv writer\n",
    "    def spider_closed(self):\n",
    "        with open(\"dmoz.csv\",\"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f,['Category','WebsiteName','WebsiteURL','WebpageTitle'])\n",
    "            writer.writeheader()\n",
    "            for data in self.itemlist:\n",
    "                writer.writerow(data)\n",
    "\n",
    "                \n",
    "    # parser\n",
    "    def parse(self, response):\n",
    "        for record in response.css('.site-item'):\n",
    "            items = {}\n",
    "            items[\"Category\"] = response.xpath('//title/text()').get()\n",
    "            items[\"WebsiteName\"] = record.css('.site-title::text').extract_first(default='')\n",
    "            items[\"WebsiteURL\"] = record.css('.title-and-desc a::attr(href)').extract_first(default='')\n",
    "            \n",
    "            if items[\"WebsiteURL\"]:\n",
    "                \n",
    "                request = response.follow(items[\"WebsiteURL\"], callback=self.get_website_title)\n",
    "                request.meta['items'] = items\n",
    "                yield request\n",
    "            self.itemlist.append(items)\n",
    "            \n",
    "    # parsing child page contents\n",
    "    def get_website_title(self,response):\n",
    "        items = response.meta['items']\n",
    "        items['WebpageTitle']=response.xpath('//title/text()').extract_first(default='').strip()\n",
    "        yield items\n",
    "        \n",
    "        \n",
    "\n",
    "cat_spider = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0',   \n",
    "})\n",
    "cat_spider.crawl(CatalogSpider)\n",
    "cat_spider.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
